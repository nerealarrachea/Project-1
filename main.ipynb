{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cbeaa83",
   "metadata": {},
   "source": [
    "# SHARK ATTACKS ðŸ¦ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0031268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "sns.set_theme(style=\"white\", palette=\"Spectral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e322a3b5",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5738fe4",
   "metadata": {},
   "source": [
    "First I downloaded the dataframe and cleaned it. The data had more than 25 thousand rows and 24 columns, but around 79% of the data was missing. So I got rid of more than 20 thousand rows and more than 10 columns which didn't add anything to my analysis. I also extracted the month from the Date column, and got rid of the day, and changed the name of some columns, to make data manipulation easier later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ddced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/narea/Desktop/ironhack/Project-1/data/attacks.csv\", encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dbd0db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f02375f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33acc44e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e961968a",
   "metadata": {},
   "source": [
    "As we can see in the following table, most of the columns are missing at least 75% of the data. That's why I got rid of missing values to get a smaller but more valuable dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7516df20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_nan = df.isna().sum()\n",
    "percent = df_nan * 100 / len(df)\n",
    "missing_values = pd.DataFrame({'Missing values': df_nan, 'Missing %': percent})\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38f85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3876f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['Age'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dcfd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nan = df.isna().sum()\n",
    "percent = df_nan * 100 / len(df)\n",
    "missing_values = pd.DataFrame({'Missing values': df_nan, 'Missing %': percent})\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c495cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop([\"Unnamed: 22\", \"Unnamed: 23\", \"href\", \"Case Number.1\", \"Case Number.2\", \"pdf\", \"Case Number\", \"href formula\", \"Investigator or Source\",\"original order\",\"Type\",\"Injury\",\"Location\",\"Area\", \"Name\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e96fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the month from the date column with regex, and deleting the date column\n",
    "df['Month'] = df['Date'].str.extract('(-\\D{3}-)', expand=True)\n",
    "# we still need to take out the (-)'s   \n",
    "regex_ = [r\"(-\\D{3}-): \", r\"-\"]\n",
    "df['Month'] = df['Month'].replace(regex=regex_, value=\"\")\n",
    "df.drop([\"Date\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a40695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the name of some columns to make it easier to work with the data. \n",
    "df['Fatal (Y/N)'] = df['Fatal (Y/N)'].str.strip().str.upper()\n",
    "df['Sex '] = df['Sex '].str.strip().str.upper()\n",
    "df = df[((df['Fatal (Y/N)']=='N') | (df['Fatal (Y/N)']=='Y')) & ((df['Sex ']=='M') | (df['Sex ']=='F'))]\n",
    "df['Sex'] = df['Sex '].str.rstrip()\n",
    "df = df.drop(\"Sex \", axis=1)\n",
    "df['Species'] = df['Species '].str.rstrip()\n",
    "df = df.drop(\"Species \", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8befcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using regex to keep just the values of the age column\n",
    "df['Age'] = df['Age'].dropna().apply(lambda x: re.findall(r\"\\d{2}\",x))  \n",
    "df['Age'] = df['Age'].str[0] \n",
    "df['Age'] = df['Age'].astype(float) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc10ff2",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66867680",
   "metadata": {},
   "source": [
    "## 1.1. Year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76624f3e",
   "metadata": {},
   "source": [
    "To explore the attacks per year I focused on the data from 1800 to 2018, and got rid of some outliers the dataframe had. As we can see in the following graph, attacks have been increasing in the last 60 years, this may be due to the increase of ocean related activities in the last decades. Still, even though there have been more attacks, the probablity of dying from one of these, has been lower each year. Even if there are more attacks nowadays, the number of fatal victims has stayed the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d4e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Year']>=1800)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91efbb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = df[['Year']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fbeb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df['Year'].value_counts().sort_index()\n",
    "%matplotlib inline\n",
    "years.plot(title=\"Shark Attacks per year\")\n",
    "plt.savefig('./images/year.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0276673",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x='Year', hue='Fatal (Y/N)', multiple='stack', kde=True)\n",
    "plt.savefig('./images/year_fatal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9755a471",
   "metadata": {},
   "source": [
    "## 1.2. Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a84d2",
   "metadata": {},
   "source": [
    "By exploring the age of the victims, it's easy to see that the youth is more affected by shark attacks, probably due to the presence of this age range in the ocean. The people most affected are the one's from age 18-20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Age']<=90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b955c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = df['Age'].value_counts().sort_index()\n",
    "sns.histplot(data=df, x='Age', hue='Fatal (Y/N)', multiple='stack')\n",
    "plt.savefig('./images/age.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b8d7fb",
   "metadata": {},
   "source": [
    "## 1.3. Sex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a0c48",
   "metadata": {},
   "source": [
    "Men are more probable to be attacked by a shark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2d327",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Sex\", hue=\"Fatal (Y/N)\")\n",
    "plt.savefig('./images/sex.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c3f17",
   "metadata": {},
   "source": [
    "## 1.4. Species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd0d2de",
   "metadata": {},
   "source": [
    "And the oscar to the shark with more attacks goes to the one and only...white shark. Steven Spielberg knew who to cast for his Oscar winning movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Species'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffffd1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharks = df['Species'].value_counts()\n",
    "sharks[sharks>36].plot.barh(color='orange')\n",
    "plt.savefig('./images/species.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5dbfa",
   "metadata": {},
   "source": [
    "## 1.5. Countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9edf70b",
   "metadata": {},
   "source": [
    "If you don't like thrilling, pulse-raising or breath-taking adventures, these are the places to avoid. If you are the opposite, these are the places to go. The 10 countries with most shark attacks are the shown in the next table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a95c489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Country'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0948a6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df['Country'].value_counts()\n",
    "countries[countries>26].plot.barh(color='orange')\n",
    "plt.savefig('./images/countries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d4b3a7",
   "metadata": {},
   "source": [
    "## 1.6. Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Activity'].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = df['Activity'].value_counts()\n",
    "activities[:10].plot.barh(color='orange')\n",
    "plt.savefig('./images/act.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca50ab",
   "metadata": {},
   "source": [
    "## H1: shark attacks are more likely to occur in the afternoon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0049f053",
   "metadata": {},
   "source": [
    "My first hypothesis was that shark attacks are more likely to occur in the afternoon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using regex to extract just the numbers of the time column and keeping the numbers smaller than 24\n",
    "# since there are some outliers in the data\n",
    "df['Time'] = df['Time'].str.extract(\"([0-9]+)\", expand=False).dropna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Time']<=24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e95021",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df, x=\"Time\")\n",
    "plt.savefig('./images/time.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc85a8a",
   "metadata": {},
   "source": [
    "## H2: summer is the season with most shark attacks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84037b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country = df['Country'].unique()\n",
    "print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e913a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a list with all the countries from the northern hemisphere and the southern hemisphere\n",
    "# and making a dictionary to know which season corresponds to each month in both hemispheres\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "season_north = {'Jan':'winter','Feb':'winter','Mar':'spring','Apr':'spring','May':'spring','Jun':'summer',\n",
    "           'Jul':'summer','Aug':'summer','Sep':'autumn','Oct':'autumn','Nov':'autumn', 'Dec':'winter'}\n",
    "season_south = {'Jan':'summer','Feb':'summer','Mar':'autumn','Apr':'autumn','May':'autumn','Jun':'winter',\n",
    "           'Jul':'winter','Aug':'winter','Sep':'spring','Oct':'spring','Nov':'spring', 'Dec':'summer'}\n",
    "north = ['USA','ENGLAND', 'COSTA RICA', 'BAHAMAS',' TONGA','AMERICAN SAMOA','ARUBA', 'AZORES','BARBADOS', 'BERMUDA', 'BELIZE','BRITISH ISLES',\n",
    "      'DOMINICAN REPUBLIC','CROATIA','CUBA','CHINA','IRAQ','ADMIRALTY ISLANDS', 'SCOTLAND','RUSSIA','PORTUGAL','PALA','IRAN','ISRAEL','ITALY','JAPAN','COLUMBIA','CANADA','CENTRAL PACIFIC',\n",
    "       'CARIBBEAN SEA','ST. MAARTIN','ST. MARTIN', 'TRINIDAD & TOBAGO', 'TURKS & CAICOS','TONGA','TAIWAN','VIETNAM','THAILAND', 'SOUTH CHINA SEA', 'SOUTH KOREA','UNITED KINGDOM',\n",
    "         'UNITED ARAB EMIRATES (UAE)','UNITED ARAB EMIRATES','SRI LANKA', 'PUERTO RICO','PHILIPPINES','TURKEY','SPAIN','SINGAPORE','PALESTINIAN TERRITORIES','SOMALIA','SIERRA LEONE',\n",
    "         'PANAMA','SENEGAL', 'SAUDI ARABIA','OKINAWA','NICARAGUA','NIGERIA','MICRONESIA','NEW BRITAIN','MID ATLANTIC OCEAN','MARSHALL ISLANDS', \n",
    "         'MALAYSIA','JAMAICA', 'INDIA', 'HONG KONG','HONDURAS','GUINEA','GUAM','GRENADA','EL SALVADOR', 'CAYMAN ISLANDS','GRAND CAYMAN','FEDERATED STATES OF MICRONESIA', 'MALTA', \n",
    "         'GREECE','FRANCE','MEXICO','NORWAY','BRITISH VIRGIN ISLANDS', 'BRITISH WEST INDIES',]\n",
    "south = ['AUSTRALIA', 'MALDIVES', 'SOUTH AFRICA', 'ARGENTINA','PAPUA NEW GUINEA', 'WESTERN SAMOA','URUGUAY','TANZANIA', 'SOLOMON ISLANDS','SAMOA','SEYCHELLES',\n",
    "         'ANDAMAN / NICOBAR ISLANDAS', 'BRAZIL','BRITISH NEW GUINEA','CHILE','CAPE VERDE','ECUADOR','FIJI','Fiji',\n",
    "      'DIEGO GARCIA','NEW GUINEA','VANUATU','VENEZUELA','NEW CALEDONIA','MOZAMBIQUE','NEW ZEALAND', 'KENYA','KIRIBATI',\n",
    "         'MADAGASCAR','MAURITIUS','FRENCH POLYNESIA','INDONESIA','EGYPT', 'INDIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b08ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function that returns either northern or southern hemisphere depending on which list the country is located\n",
    "def hemisphere(country):\n",
    "    if country in north:\n",
    "        return 'Northern Hemisphere'\n",
    "    elif country in south:\n",
    "        return 'Southern Hemisphere'\n",
    "    else:\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column with the values\n",
    "df['Hemisphere'] = df['Country'].apply(lambda x: hemisphere(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3be8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df[\"Hemisphere\"])\n",
    "plt.savefig('./images/hemisphere.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def season(hemisphere,value):\n",
    "    if hemisphere == 'Southern Hemisphere':\n",
    "        return season_south[value]\n",
    "    elif hemisphere == 'Northern Hemisphere':\n",
    "        return season_north[value]\n",
    "    else:\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f3322",
   "metadata": {},
   "outputs": [],
   "source": [
    "season('Southern Hemisphere','Jun')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1567df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this worked before, and I got the graph and everything, but I don't know what I changed that it stoped working\n",
    "# i am going to keep trying to make it work. \n",
    "season(df['Hemisphere'],df['Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6433d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Season'] = df.apply(lambda x: season(x['Hemisphere'], x['Month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69b94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## sns.counttplot(x=df[\"Season\"], hue= df['Hemisphere'])\n",
    "## plt.savefig('./images/season.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e9d67a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
